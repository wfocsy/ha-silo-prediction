#!/usr/bin/env python3
"""
TECH ADAT KORREL√ÅCI√ì ELEMZ√âSE

√ñsszehasonl√≠tjuk a tech adatok alapj√°n v√°rhat√≥ fogy√°st
a val√≥s m√©rt fogy√°ssal.

C√©l: Meg√°llap√≠tani, mennyire pontosak a tech adatok.
"""
import csv
import numpy as np
from datetime import datetime, timedelta

# Technol√≥giai takarm√°ny adatok (g/mad√°r/nap)
TECH_FEED_DATA = {
    0: 0, 1: 0, 2: 16, 3: 20, 4: 24, 5: 27, 6: 31, 7: 35, 8: 39, 9: 44,
    10: 48, 11: 52, 12: 57, 13: 62, 14: 67, 15: 72, 16: 77, 17: 83, 18: 88, 19: 94,
    20: 100, 21: 105, 22: 111, 23: 117, 24: 122, 25: 128, 26: 134, 27: 139, 28: 145, 29: 150,
    30: 156, 31: 161, 32: 166, 33: 171, 34: 176, 35: 180, 36: 185, 37: 189, 38: 193, 39: 197,
    40: 201, 41: 204, 42: 207, 43: 211, 44: 213, 45: 216, 46: 219, 47: 221, 48: 223, 49: 225,
    50: 227
}

def load_csv_data():
    """CSV bet√∂lt√©se"""
    data = []
    with open("/data/Blokkhistory3_4.csv", "r") as f:
        reader = csv.DictReader(f)
        for row in reader:
            try:
                state = row['state']
                if state in ['unavailable', 'unknown', '']:
                    continue
                weight = float(state)
                timestamp = datetime.fromisoformat(row['last_changed'].replace('Z', '+00:00'))
                data.append((timestamp, weight))
            except:
                continue
    return data

def resample_6hourly(data):
    """6 √≥r√°s mintav√©telez√©s"""
    timestamps = np.array([t for t, w in data])
    weights = np.array([w for t, w in data])

    start_time = timestamps[0]
    end_time = timestamps[-1]

    current = start_time.replace(hour=(start_time.hour // 6) * 6, minute=0, second=0, microsecond=0)
    sample_data = []

    while current <= end_time:
        window_start = current - timedelta(hours=3)
        window_end = current + timedelta(hours=3)

        mask = (timestamps >= window_start) & (timestamps <= window_end)
        if np.any(mask):
            avg_weight = np.mean(weights[mask])
            sample_data.append((current, avg_weight))

        current += timedelta(hours=6)

    return sample_data

def create_normalized_curve(data_6h):
    """Normaliz√°lt g√∂rbe (felt√∂lt√©sek n√©lk√ºl)"""
    normalized = []
    cumulative_refill = 0

    for i, (timestamp, weight) in enumerate(data_6h):
        if i > 0:
            weight_change = weight - data_6h[i-1][1]
            if weight_change > 3000:
                cumulative_refill += weight_change

        normalized_weight = weight - cumulative_refill
        normalized.append((timestamp, normalized_weight))

    return normalized

def analyze_tech_correlation(normalized_curve, cycle_start, bird_count):
    """
    Tech adat vs val√≥s fogy√°s korrel√°ci√≥ elemz√©se
    """
    print("\n" + "=" * 80)
    print("üî¨ TECH ADAT KORREL√ÅCI√ì ELEMZ√âSE")
    print("=" * 80)
    print(f"\nüìä Param√©terek:")
    print(f"   Ciklus kezdet: {cycle_start.strftime('%Y-%m-%d')}")
    print(f"   Mad√°rsz√°m: {bird_count:,}")

    # Ciklus ut√°ni adatok
    cycle_data = [(t, w) for t, w in normalized_curve if t >= cycle_start]

    if len(cycle_data) < 8:
        print("‚ùå Nincs el√©g adat")
        return

    # Napi √∂sszehasonl√≠t√°s
    results = []

    for i in range(4, len(cycle_data)):  # 4 adatpont = 24 √≥ra
        # 24 √≥r√°s ablak
        prev_time, prev_weight = cycle_data[i-4]
        curr_time, curr_weight = cycle_data[i]

        # Val√≥s napi fogy√°s
        actual_daily_kg = prev_weight - curr_weight

        if actual_daily_kg < 10:  # Minimum fogy√°s
            continue

        # Nevel√©si nap
        day = (curr_time - cycle_start).days

        # Tech adat alapj√°n v√°rhat√≥ fogy√°s
        tech_per_bird_g = TECH_FEED_DATA.get(day, 150)
        tech_daily_kg = (tech_per_bird_g * bird_count) / 1000

        # Elt√©r√©s
        difference_kg = actual_daily_kg - tech_daily_kg
        difference_percent = (difference_kg / tech_daily_kg) * 100 if tech_daily_kg > 0 else 0

        results.append({
            'day': day,
            'date': curr_time,
            'actual_kg': actual_daily_kg,
            'tech_kg': tech_daily_kg,
            'diff_kg': difference_kg,
            'diff_percent': difference_percent
        })

    if not results:
        print("‚ùå Nincs √∂sszehasonl√≠that√≥ adat")
        return

    # Statisztik√°k
    actual_values = [r['actual_kg'] for r in results]
    tech_values = [r['tech_kg'] for r in results]
    diff_values = [r['diff_kg'] for r in results]
    diff_percent_values = [r['diff_percent'] for r in results]

    print(f"\nüìà √ñSSZES√çTETT STATISZTIK√ÅK ({len(results)} nap):")
    print("-" * 80)
    print(f"\n  VAL√ìS FOGY√ÅS:")
    print(f"    √Åtlag: {np.mean(actual_values):.0f} kg/nap")
    print(f"    Min:   {np.min(actual_values):.0f} kg/nap ({results[np.argmin(actual_values)]['day']}. nap)")
    print(f"    Max:   {np.max(actual_values):.0f} kg/nap ({results[np.argmax(actual_values)]['day']}. nap)")

    print(f"\n  TECH ALAP√ö V√ÅRHAT√ì FOGY√ÅS:")
    print(f"    √Åtlag: {np.mean(tech_values):.0f} kg/nap")
    print(f"    Min:   {np.min(tech_values):.0f} kg/nap")
    print(f"    Max:   {np.max(tech_values):.0f} kg/nap")

    print(f"\n  ELT√âR√âS (Val√≥s - Tech):")
    print(f"    √Åtlag: {np.mean(diff_values):+.0f} kg/nap ({np.mean(diff_percent_values):+.1f}%)")
    print(f"    Min:   {np.min(diff_values):+.0f} kg/nap ({np.min(diff_percent_values):+.1f}%)")
    print(f"    Max:   {np.max(diff_values):+.0f} kg/nap ({np.max(diff_percent_values):+.1f}%)")

    # Korrel√°ci√≥
    from scipy import stats as sp_stats
    correlation, p_value = sp_stats.pearsonr(actual_values, tech_values)

    print(f"\n  üìä KORREL√ÅCI√ì:")
    print(f"    Pearson r: {correlation:.3f}")
    print(f"    p-√©rt√©k: {p_value:.6f}")

    if correlation > 0.9:
        print(f"    ‚úÖ NAGYON ER≈ê KORREL√ÅCI√ì!")
    elif correlation > 0.7:
        print(f"    ‚úÖ ER≈ê KORREL√ÅCI√ì!")
    elif correlation > 0.5:
        print(f"    ‚ö†Ô∏è K√ñZEPES KORREL√ÅCI√ì")
    else:
        print(f"    ‚ùå GYENGE KORREL√ÅCI√ì")

    # R√©szletes lista (els≈ë 10 nap + utols√≥ 10 nap)
    print(f"\nüìã R√âSZLETES √ñSSZEHASONL√çT√ÅS:")
    print("-" * 80)
    print(f"{'Nap':<5} {'D√°tum':<12} {'Val√≥s':<10} {'Tech':<10} {'Elt√©r√©s':<15}")
    print("-" * 80)

    # Els≈ë 10
    for r in results[:10]:
        print(f"{r['day']:>3}. {r['date'].strftime('%m-%d'):<12} "
              f"{r['actual_kg']:>7.0f} kg  {r['tech_kg']:>7.0f} kg  "
              f"{r['diff_kg']:+7.0f} kg ({r['diff_percent']:+5.1f}%)")

    if len(results) > 20:
        print("  ...")

        # Utols√≥ 10
        for r in results[-10:]:
            print(f"{r['day']:>3}. {r['date'].strftime('%m-%d'):<12} "
                  f"{r['actual_kg']:>7.0f} kg  {r['tech_kg']:>7.0f} kg  "
                  f"{r['diff_kg']:+7.0f} kg ({r['diff_percent']:+5.1f}%)")

    # K√∂vetkeztet√©s
    print(f"\nüí° K√ñVETKEZTET√âS:")
    print("-" * 80)

    avg_diff = np.mean(diff_values)
    avg_diff_pct = np.mean(diff_percent_values)

    if abs(avg_diff_pct) < 5:
        print(f"‚úÖ A tech adatok KIV√ÅL√ìAN illeszkednek a val√≥s fogy√°shoz!")
        print(f"   √Åtlagos elt√©r√©s: {avg_diff_pct:+.1f}% (< 5%)")
    elif abs(avg_diff_pct) < 10:
        print(f"‚úÖ A tech adatok J√ìL illeszkednek a val√≥s fogy√°shoz!")
        print(f"   √Åtlagos elt√©r√©s: {avg_diff_pct:+.1f}% (< 10%)")
    elif abs(avg_diff_pct) < 20:
        print(f"‚ö†Ô∏è A tech adatok ELFOGADHAT√ìAN illeszkednek a val√≥s fogy√°shoz.")
        print(f"   √Åtlagos elt√©r√©s: {avg_diff_pct:+.1f}% (< 20%)")
    else:
        print(f"‚ùå A tech adatok NEM illeszkednek j√≥l a val√≥s fogy√°shoz!")
        print(f"   √Åtlagos elt√©r√©s: {avg_diff_pct:+.1f}% (> 20%)")

    if avg_diff > 0:
        print(f"\n   ‚Üí A madarak T√ñBBET esznek, mint a tech adat!")
        print(f"   ‚Üí Korrekci√≥s faktor: {1 + (avg_diff / np.mean(tech_values)):.3f}x")
    else:
        print(f"\n   ‚Üí A madarak KEVESEBBET esznek, mint a tech adat!")
        print(f"   ‚Üí Korrekci√≥s faktor: {1 + (avg_diff / np.mean(tech_values)):.3f}x")

    return results

def main():
    print("üî¨ TECH ADAT KORREL√ÅCI√ì ELEMZ√âSE")
    print("=" * 80)
    print()

    # Adatok bet√∂lt√©se
    data = load_csv_data()
    data_6h = resample_6hourly(data)

    print(f"‚úÖ {len(data)} rekord bet√∂ltve")
    print(f"üìà {len(data_6h)} mintav√©telezett adatpont (6 √≥r√°nk√©nt)")

    # Normaliz√°lt g√∂rbe
    normalized = create_normalized_curve(data_6h)

    # 0. nap √©s mad√°rsz√°m (hard-coded a kor√°bbi eredm√©nyek alapj√°n)
    cycle_start = datetime(2025, 10, 20, 6, 0, tzinfo=data_6h[0][0].tzinfo)
    bird_count = 19524  # Kor√°bbi sz√°m√≠t√°s eredm√©nye

    # Korrel√°ci√≥ elemz√©se
    analyze_tech_correlation(normalized, cycle_start, bird_count)

    print("\n" + "=" * 80)
    print("‚úÖ ELEMZ√âS BEFEJEZVE")
    print("=" * 80)

if __name__ == "__main__":
    main()
