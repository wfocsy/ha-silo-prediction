#!/usr/bin/env python3
"""
Silo Prediction Home Assistant Add-on - Multi-Silo Support
Intelligens sil√≥ ki√ºr√ºl√©si el≈ërejelz√©s technol√≥giai fogyaszt√°si adatok alapj√°n
"""

import os
import json
import time
import logging
import requests
import numpy as np
import pytz
import csv
from datetime import datetime, timedelta
from typing import List, Tuple, Dict, Optional
from scipy import stats

# Logging be√°ll√≠t√°sa id≈ëb√©lyeggel
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.FileHandler('/app/logs/silo_prediction.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Timezone be√°ll√≠t√°sa - Home Assistant timezone-ja
try:
    LOCAL_TZ = pytz.timezone('Europe/Budapest')
    logger.info(f"‚úÖ Timezone be√°ll√≠tva: Europe/Budapest")
except Exception as e:
    LOCAL_TZ = pytz.UTC
    logger.warning(f"‚ö†Ô∏è Europe/Budapest timezone nem el√©rhet≈ë ({e}), UTC-t haszn√°lunk")


class TechnologicalFeedData:
    """
    Technol√≥giai takarm√°ny fogyaszt√°si adatok kezel√©se
    CSV f√°jlb√≥l bet√∂lt√©s √©s interpol√°ci√≥
    """

    def __init__(self, csv_path: str = '/app/tech_feed_data.csv'):
        self.csv_path = csv_path
        self.feed_data = {}  # {day: grams_per_day}
        self._load_csv()

    def _load_csv(self):
        """CSV f√°jl bet√∂lt√©se"""
        try:
            with open(self.csv_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                next(reader)  # Fejl√©c √°tugr√°sa

                for row in reader:
                    if len(row) >= 2:
                        # " 10. nap" -> 10
                        day_str = row[0].strip().replace('.', '').replace('nap', '').strip()
                        # " 48 g" -> 48
                        intake_str = row[1].strip().replace('g', '').strip()

                        try:
                            day = int(day_str)
                            intake_g = int(intake_str)
                            self.feed_data[day] = intake_g
                        except ValueError:
                            continue

            logger.info(f"‚úÖ Technol√≥giai adatok bet√∂ltve: {len(self.feed_data)} nap ({min(self.feed_data.keys())}-{max(self.feed_data.keys())} nap)")

        except FileNotFoundError:
            logger.error(f"‚ùå Technol√≥giai CSV nem tal√°lhat√≥: {self.csv_path}")
            # Fallback: be√©getett adatok
            self._load_fallback_data()
        except Exception as e:
            logger.error(f"‚ùå Hiba a CSV bet√∂lt√©se sor√°n: {e}")
            self._load_fallback_data()

    def _load_fallback_data(self):
        """Be√©getett fallback adatok, ha a CSV nem el√©rhet≈ë"""
        logger.warning("‚ö†Ô∏è Fallback: be√©getett technol√≥giai adatok haszn√°lata")
        self.feed_data = {
            0: 0, 1: 0, 2: 16, 3: 20, 4: 24, 5: 27, 6: 31, 7: 35, 8: 39, 9: 44,
            10: 48, 11: 52, 12: 57, 13: 62, 14: 67, 15: 72, 16: 77, 17: 83, 18: 88, 19: 94,
            20: 100, 21: 105, 22: 111, 23: 117, 24: 122, 25: 128, 26: 134, 27: 139, 28: 145, 29: 150,
            30: 156, 31: 161, 32: 166, 33: 171, 34: 176, 35: 180, 36: 185, 37: 189, 38: 193, 39: 197,
            40: 201, 41: 204, 42: 207, 43: 211, 44: 213, 45: 216, 46: 219, 47: 221, 48: 223, 49: 225,
            50: 227
        }

    def get_daily_intake_per_bird(self, day: int) -> float:
        """
        Egy mad√°r v√°rhat√≥ napi takarm√°ny felv√©tele

        Args:
            day: Nevel√©si nap (0-t√≥l sz√°m√≠tva)

        Returns:
            Takarm√°ny felv√©tel grammban/nap (1 mad√°r)
        """
        if day < 0:
            return 0.0

        # Ha t√∫ll√©pt√ºk a t√°bl√°zat v√©g√©t, plat√≥ √©rt√©k
        if day > max(self.feed_data.keys()):
            return float(self.feed_data[max(self.feed_data.keys())])

        # Pontos √©rt√©k
        if day in self.feed_data:
            return float(self.feed_data[day])

        # Line√°ris interpol√°ci√≥ k√©t ismert pont k√∂z√∂tt
        lower_day = max([d for d in self.feed_data.keys() if d < day], default=0)
        upper_day = min([d for d in self.feed_data.keys() if d > day], default=max(self.feed_data.keys()))

        if lower_day == upper_day:
            return float(self.feed_data[lower_day])

        # Line√°ris interpol√°ci√≥
        lower_intake = self.feed_data[lower_day]
        upper_intake = self.feed_data[upper_day]

        fraction = (day - lower_day) / (upper_day - lower_day)
        interpolated = lower_intake + fraction * (upper_intake - lower_intake)

        return interpolated


class SiloPredictor:
    """Egy silo el≈ërejelz√©si logik√°ja technol√≥giai adatok alapj√°n"""

    def __init__(self, ha_url: str, ha_token: str, entity_id: str, sensor_name: str,
                 refill_threshold: int, max_capacity: int, prediction_days: int = 45,
                 tech_csv_path: str = '/app/tech_feed_data.csv'):
        self.ha_url = ha_url
        self.ha_token = ha_token
        self.entity_id = entity_id
        self.sensor_name = sensor_name
        self.refill_threshold = refill_threshold
        self.max_capacity = max_capacity
        self.prediction_days = prediction_days  # 45 nap aj√°nlott

        # Technol√≥giai fogyaszt√°si adatok bet√∂lt√©se
        self.tech_data = TechnologicalFeedData(csv_path=tech_csv_path)

        # Ciklus adatok (bet√∂lt√©s HA szenzorb√≥l)
        self.cycle_start_date = None  # 0. nap d√°tuma
        self.bird_count = None  # Mad√°r darabsz√°m

        self.headers = {
            'Authorization': f'Bearer {self.ha_token}',
            'Content-Type': 'application/json'
        }

        logger.info(f"üì¶ Silo inicializ√°lva: {self.sensor_name} ({self.entity_id})")
        logger.info(f"üìä El≈ërejelz√©si id≈ëablak: {self.prediction_days} nap")

        # Bet√∂ltj√ºk a ciklus adatokat (ha vannak)
        self._load_cycle_data()

    def _load_cycle_data(self):
        """Ciklus adatok bet√∂lt√©se a HA szenzor attrib√∫tumaib√≥l"""
        sensor_entity_id = f"sensor.{self.sensor_name.lower().replace(' ', '_')}"
        url = f"{self.ha_url}/api/states/{sensor_entity_id}"

        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                attributes = data.get('attributes', {})

                # Ciklus kezdete (0. nap)
                cycle_start_str = attributes.get('cycle_start_date')
                if cycle_start_str:
                    self.cycle_start_date = datetime.fromisoformat(cycle_start_str).replace(tzinfo=LOCAL_TZ)
                    logger.info(f"üì• [{self.sensor_name}] Ciklus kezdete bet√∂ltve: {self.cycle_start_date.strftime('%Y-%m-%d')}")

                # Mad√°r darabsz√°m
                self.bird_count = attributes.get('bird_count')
                if self.bird_count:
                    logger.info(f"üì• [{self.sensor_name}] Mad√°r darabsz√°m bet√∂ltve: {self.bird_count}")

            else:
                logger.debug(f"‚ÑπÔ∏è [{self.sensor_name}] Szenzor m√©g nem l√©tezik, nincs ciklus adat")
        except Exception as e:
            logger.debug(f"‚ÑπÔ∏è [{self.sensor_name}] Ciklus adatok bet√∂lt√©se nem siker√ºlt: {e}")

    def _save_cycle_data(self, cycle_start_date: datetime, bird_count: int):
        """Ciklus adatok ment√©se (0. nap, mad√°r darabsz√°m)"""
        self.cycle_start_date = cycle_start_date
        self.bird_count = bird_count
        logger.info(f"üíæ [{self.sensor_name}] Ciklus adatok mentve: "
                   f"kezdet={cycle_start_date.strftime('%Y-%m-%d')}, madarak={bird_count}")

    def get_historical_data(self) -> List[Tuple[datetime, float]]:
        """T√∂rt√©neti adatok lek√©r√©se a Home Assistant API-b√≥l"""
        # Lok√°lis id≈ëben sz√°molunk
        end_time = datetime.now(LOCAL_TZ)
        start_time = end_time - timedelta(days=self.prediction_days)

        logger.info(f"üìä [{self.sensor_name}] Adatok lek√©r√©se: {start_time.strftime('%Y-%m-%d %H:%M')} - {end_time.strftime('%Y-%m-%d %H:%M')}")

        url = f"{self.ha_url}/api/history/period/{start_time.isoformat()}"
        params = {
            'filter_entity_id': self.entity_id,
            'end_time': end_time.isoformat()
        }

        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()

            data = response.json()

            if not data or not data[0]:
                logger.warning(f"‚ùå [{self.sensor_name}] Nincs adat a v√°laszban")
                return []

            # Adatok feldolgoz√°sa - UTC-b≈ël lok√°lis id≈ëre konvert√°l√°s
            processed_data = []
            for entry in data[0]:
                try:
                    # HA UTC-ben k√ºldi, konvert√°ljuk lok√°lisra
                    timestamp_utc = datetime.fromisoformat(entry['last_changed'].replace('Z', '+00:00'))
                    # Konvert√°l√°s lok√°lis id≈ëz√≥n√°ra
                    timestamp = timestamp_utc.astimezone(LOCAL_TZ)

                    state = entry.get('state', '0')
                    if state in ['unknown', 'unavailable', 'null', None]:
                        continue

                    weight = float(state)
                    if 0 <= weight <= 50000:
                        processed_data.append((timestamp, weight))

                except (ValueError, KeyError, TypeError):
                    continue

            processed_data.sort(key=lambda x: x[0])

            logger.info(f"‚úÖ [{self.sensor_name}] {len(processed_data)} adatpont bet√∂ltve")
            return processed_data

        except requests.RequestException as e:
            logger.error(f"‚ùå [{self.sensor_name}] API hiba: {e}")
            return []

    def sample_daily_data(self, data: List[Tuple[datetime, float]]) -> List[Tuple[datetime, float]]:
        """
        6 √ìR√ÅNK√âNTI mintav√©telez√©s (napi 4 adatpont) - 7:00-kor nap v√°lt√°s

        Minden 6 √≥r√°s peri√≥dusb√≥l (7:00, 13:00, 19:00, 1:00) egy √°tlagos s√∫ly√©rt√©ket k√©sz√≠t.

        INDOKL√ÅS:
        A nevel√©si ciklus v√©g√©n a fogy√°si r√°ta exponenci√°lisan n√∂vekszik:
        - 1-2. felt√∂lt√©s: 7-9 nap
        - 2-3. felt√∂lt√©s: 5 nap
        - 3-4. felt√∂lt√©s: 4 nap
        - 4+. felt√∂lt√©s: 2-3 nap

        Napi 1 adatpont k√©s≈ëbbi f√°zisban pontatlan lenne!

        Args:
            data: Nyers adatok

        Returns:
            List of (timestamp, √°tlag_s√∫ly) - 6 √≥r√°nk√©nt
        """
        if not data:
            return []

        # 6 √≥r√°s id≈ëszakokra csoportos√≠t√°s
        # Peri√≥dusok: 7:00-12:59, 13:00-18:59, 19:00-0:59, 1:00-6:59
        period_buckets = {}

        for timestamp, weight in data:
            # Nap kulcs (7:00-os nap v√°lt√°ssal)
            if timestamp.hour < 7:
                day_key = timestamp.date() - timedelta(days=1)
            else:
                day_key = timestamp.date()

            # Peri√≥dus meghat√°roz√°sa (0-3: 7:00, 13:00, 19:00, 1:00)
            if 7 <= timestamp.hour < 13:
                period = 0  # 7:00-12:59
            elif 13 <= timestamp.hour < 19:
                period = 1  # 13:00-18:59
            elif 19 <= timestamp.hour < 24:
                period = 2  # 19:00-23:59
            else:  # 0 <= timestamp.hour < 7
                period = 3  # 0:00-6:59 (el≈ëz≈ë nap folytat√°sa)

            period_key = (day_key, period)

            if period_key not in period_buckets:
                period_buckets[period_key] = []

            period_buckets[period_key].append(weight)

        # Peri√≥dus √°tlagok sz√°m√≠t√°sa
        sampled_data = []
        for (day_key, period) in sorted(period_buckets.keys()):
            weights = period_buckets[(day_key, period)]
            avg_weight = np.mean(weights)

            # Timestamp: a peri√≥dus kezdete
            if period == 0:
                period_timestamp = datetime.combine(day_key, datetime.min.time()).replace(hour=7, tzinfo=LOCAL_TZ)
            elif period == 1:
                period_timestamp = datetime.combine(day_key, datetime.min.time()).replace(hour=13, tzinfo=LOCAL_TZ)
            elif period == 2:
                period_timestamp = datetime.combine(day_key, datetime.min.time()).replace(hour=19, tzinfo=LOCAL_TZ)
            else:  # period == 3
                # 1:00 (k√∂vetkez≈ë nap 1:00-ja, de m√©g az el≈ëz≈ë naphoz tartozik)
                period_timestamp = datetime.combine(day_key + timedelta(days=1), datetime.min.time()).replace(hour=1, tzinfo=LOCAL_TZ)

            sampled_data.append((period_timestamp, avg_weight))

        if sampled_data:
            logger.info(f"üìà [{self.sensor_name}] {len(sampled_data)} adatpont mintav√©telezve (6 √≥r√°nk√©nt, napi 4 minta) "
                       f"({sampled_data[0][0].strftime('%Y-%m-%d %H:%M')} - {sampled_data[-1][0].strftime('%Y-%m-%d %H:%M')})")

        return sampled_data

    def detect_refills(self, data: List[Tuple[datetime, float]]) -> Tuple[List[Tuple[datetime, float]], Optional[datetime]]:
        """
        Felt√∂lt√©sek detekt√°l√°sa √©s csak az utols√≥ felt√∂lt√©s UT√ÅNI adatok megtart√°sa

        Returns:
            Tuple: (cleaned_data, last_refill_timestamp)
                   last_refill_timestamp: None ha nem volt felt√∂lt√©s, k√ºl√∂nben az utols√≥ felt√∂lt√©s id≈ëpontja
        """
        if len(data) < 2:
            return data, None

        last_refill_index = -1
        last_refill_timestamp = None

        for i in range(1, len(data)):
            prev_weight = data[i-1][1]
            curr_weight = data[i][1]
            weight_change = curr_weight - prev_weight

            if weight_change > 3000:
                logger.info(f"üîÑ [{self.sensor_name}] Felt√∂lt√©s detekt√°lva: {data[i-1][0]} -> {data[i][0]}, "
                           f"S√∫lyv√°ltoz√°s: +{weight_change:.0f}kg")
                last_refill_index = i
                last_refill_timestamp = data[i][0]

        if last_refill_index >= 0:
            cleaned_data = data[last_refill_index:]
            logger.info(f"‚úÖ [{self.sensor_name}] Utols√≥ felt√∂lt√©s ut√°n: {len(cleaned_data)} adatpont ({data[last_refill_index][0]})")
        else:
            cleaned_data = data
            logger.info(f"‚úÖ [{self.sensor_name}] Nem volt felt√∂lt√©s, {len(cleaned_data)} adatpont haszn√°lva")

        return cleaned_data, last_refill_timestamp

    def detect_cycle_start(self, data: List[Tuple[datetime, float]]) -> Optional[datetime]:
        """
        0. nap detekt√°l√°sa: INTELLIGENS els≈ë felt√∂lt√©s detekt√°l√°s + 100kg+ s√∫lycs√∂kken√©s napja

        Logika (K√âTL√âPCS≈êS):
        1. ELS≈êDLEGES: Keres√ºnk ~5 napos "csend" peri√≥dust (el≈ëz≈ë ciklus v√©ge):
           - Sil√≥ s√∫lya < 1000 kg
           - Nincs jelent≈ës fogyaszt√°s (< 50 kg/nap)
           - Ezt k√∂vet≈ë 3000kg+ ugr√°s = ELS≈ê FELT√ñLT√âS (√∫j ciklus kezdete)
        2. FALLBACK: Ha nincs csend peri√≥dus, keres√ºnk nagy (10000kg+) felt√∂lt√©st
           - Ez val√≥sz√≠n≈±leg ciklus kezd≈ë felt√∂lt√©s
        3. Ut√°na keress√ºk az els≈ë 100kg+ cs√∂kken√©st egy nap alatt
        4. Ez lesz a 0. nap (√°llom√°ny √©rkez√©se)

        Args:
            data: Mintav√©telezett adatok (6 √≥r√°nk√©nt)

        Returns:
            0. nap d√°tuma vagy None
        """
        if len(data) < 7:  # Minimum 7 nap adat kell
            return None

        # 1. ELS≈êDLEGES: Csend peri√≥dus + els≈ë felt√∂lt√©s keres√©se
        first_refill_index = -1

        for i in range(5, len(data)):  # Legal√°bb 5 nap m√∫ltbeli adat kell
            # El≈ëz≈ë 5 nap vizsg√°lata (csend peri√≥dus?)
            silence_period = True
            for j in range(i - 5, i):
                weight = data[j][1]

                # S√∫ly t√∫l magas (> 1000 kg) ‚Üí nem csend peri√≥dus
                if weight > 1000:
                    silence_period = False
                    break

                # Van fogyaszt√°s (> 50 kg/nap)
                if j > 0:
                    daily_change = abs(data[j][1] - data[j-1][1])
                    if daily_change > 50:
                        silence_period = False
                        break

            # Ha csend peri√≥dus, √©s most j√∂n egy 3000kg+ ugr√°s ‚Üí ELS≈ê FELT√ñLT√âS
            if silence_period and i < len(data):
                weight_change = data[i][1] - data[i-1][1]

                if weight_change > 3000:
                    first_refill_index = i
                    logger.info(f"üìç [{self.sensor_name}] Csend peri√≥dus detekt√°lva: "
                               f"{data[i-5][0].strftime('%Y-%m-%d')} - {data[i-1][0].strftime('%Y-%m-%d')} "
                               f"(s√∫ly < 1000 kg, nincs fogyaszt√°s)")
                    logger.info(f"üìç [{self.sensor_name}] ELS≈ê FELT√ñLT√âS (csend ut√°n): {data[i][0].strftime('%Y-%m-%d')}, "
                               f"+{weight_change:.0f} kg ‚Üí s√∫ly: {data[i][1]:.0f} kg")
                    break

        # 2. FALLBACK: Ha nincs csend peri√≥dus, keres√ºnk nagy (5000kg+) felt√∂lt√©st
        if first_refill_index < 0:
            logger.info(f"üîç [{self.sensor_name}] Csend peri√≥dus nem tal√°lhat√≥, alternat√≠v m√≥dszer: nagy felt√∂lt√©s keres√©se...")

            for i in range(1, len(data)):
                weight_change = data[i][1] - data[i-1][1]

                # Nagy felt√∂lt√©s (5000kg+) = val√≥sz√≠n≈±leg ciklus kezd≈ë felt√∂lt√©s
                # Cs√∂kkentve 10000-r≈ël 5000-re, mert a purge_keep_days=10 miatt nincs el√©g adat a csend peri√≥dus detekt√°l√°shoz
                if weight_change > 5000:
                    first_refill_index = i
                    logger.info(f"üìç [{self.sensor_name}] NAGY FELT√ñLT√âS detekt√°lva (ciklus kezdet): {data[i][0].strftime('%Y-%m-%d')}, "
                               f"+{weight_change:.0f} kg ‚Üí s√∫ly: {data[i][1]:.0f} kg")
                    break

        if first_refill_index < 0:
            logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Nem tal√°lhat√≥ ciklus kezd≈ë felt√∂lt√©s (sem csend ut√°n, sem nagy felt√∂lt√©s)")
            return None

        # 3. Els≈ë felt√∂lt√©s ut√°n keres√©s 100kg+ napi cs√∂kken√©sre
        for i in range(first_refill_index + 1, len(data)):
            prev_day_weight = data[i - 1][1]
            current_weight = data[i][1]
            daily_consumption = prev_day_weight - current_weight

            if daily_consumption > 100:  # 100kg+ fogyaszt√°s egy nap alatt
                cycle_start = data[i][0]
                logger.info(f"üê£ [{self.sensor_name}] 0. NAP DETEKT√ÅLVA: {cycle_start.strftime('%Y-%m-%d')}, "
                           f"napi fogyaszt√°s: {daily_consumption:.0f} kg")
                return cycle_start

        logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] 0. nap nem tal√°lhat√≥ (nincs 100kg+ napi fogyaszt√°s felt√∂lt√©s ut√°n)")
        return None

    def create_continuous_curve(self, data: List[Tuple[datetime, float]],
                                cycle_start: datetime) -> List[Tuple[datetime, float, int, float]]:
        """
        Folyamatos fogy√°si g√∂rbe k√©sz√≠t√©se felt√∂lt√©sek kisz≈±r√©s√©vel

        A felt√∂lt√©sek √©rt√©k√©t "kivonjuk", mintha folyamatos lenne a g√∂rbe.
        Minden adatponthoz hozz√°rendelj√ºk a nevel√©si napot (0-t√≥l) √©s pontos id≈ët (napokban).

        Args:
            data: Mintav√©telezett adatok (6 √≥r√°nk√©nt)
            cycle_start: 0. nap id≈ëpontja

        Returns:
            List of (timestamp, normalized_weight, day_in_cycle, exact_day_float)
        """
        if not data or not cycle_start:
            return []

        continuous_data = []
        cumulative_refill_offset = 0  # √ñsszes felt√∂lt√©s s√∫lya (amit le kell vonni)

        for i, (timestamp, weight) in enumerate(data):
            # Felt√∂lt√©s detekt√°l√°s
            if i > 0:
                prev_weight = data[i-1][1]
                weight_change = weight - prev_weight

                if weight_change > 3000:  # Felt√∂lt√©s
                    refill_amount = weight_change
                    cumulative_refill_offset += refill_amount
                    logger.info(f"üîÑ [{self.sensor_name}] Felt√∂lt√©s normaliz√°l√°s: {timestamp.strftime('%Y-%m-%d %H:%M')}, "
                               f"+{refill_amount:.0f} kg (kumulat√≠v offset: {cumulative_refill_offset:.0f} kg)")

            # Normaliz√°lt s√∫ly: mintha nem lettek volna felt√∂lt√©sek
            normalized_weight = weight - cumulative_refill_offset

            # Nevel√©si nap sz√°m√≠t√°sa (0-t√≥l) - NAP V√ÅLT√ÅS 7:00-KOR!
            # Ha 7:00 el≈ëtt vagyunk, az el≈ëz≈ë naphoz tartozik
            adjusted_timestamp = timestamp
            if timestamp.hour < 7:
                # 0:00-6:59 ‚Üí el≈ëz≈ë nap r√©sze
                adjusted_timestamp = timestamp - timedelta(hours=timestamp.hour + 17)  # Visszamegy√ºnk az el≈ëz≈ë nap 7:00-j√°hoz

            days_since_start = (adjusted_timestamp - cycle_start).total_seconds() / 86400
            day_in_cycle = int(days_since_start)
            exact_day = days_since_start  # Pontos nap t√∂rt √©rt√©kkel (pl. 5.25 = 5. nap d√©lut√°n)

            # Csak a cycle_start ut√°ni adatokat tartjuk meg
            if days_since_start >= 0:
                continuous_data.append((timestamp, normalized_weight, day_in_cycle, exact_day))

        logger.info(f"‚úÖ [{self.sensor_name}] Folyamatos g√∂rbe: {len(continuous_data)} adatpont (6 √≥r√°nk√©nt), "
                   f"{continuous_data[0][2]}-{continuous_data[-1][2]} nap k√∂z√∂tt")

        return continuous_data

    def calculate_daily_bird_count(self, continuous_data: List[Tuple[datetime, float, int, float]]) -> Dict[int, int]:
        """
        Mad√°r darabsz√°m kalkul√°ci√≥ naponta - 6 √ìR√ÅNK√âNTI MINT√ÅK ALAPJ√ÅN

        FONTOS LOGIKA:
        - NAPI √∂sszes√≠tett fogyaszt√°st sz√°molunk (4x6√≥ra = 24√≥ra)
        - Csak a 7:00-as adatpontokat haszn√°ljuk √∂sszehasonl√≠t√°sra
        - Mai 7:00 s√∫ly - Tegnapi 7:00 s√∫ly = TEGNAPI fogyaszt√°s
        - Tegnapi tech adatot haszn√°ljuk (mert az a nap fogyott)

        Args:
            continuous_data: [(timestamp, normalized_weight, day_in_cycle, exact_day), ...]
                             6 √≥r√°nk√©nti adatok

        Returns:
            {day: bird_count}
        """
        if not continuous_data or len(continuous_data) < 8:  # Minimum 2 nap x 4 adatpont kell
            return {}

        bird_counts = {}

        # Csak 7:00-as adatpontokat sz≈±rj√ºk ki
        daily_7am_data = [(ts, w, day, exact) for ts, w, day, exact in continuous_data if ts.hour == 7]

        if len(daily_7am_data) < 2:
            logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Nincs el√©g 7:00-as adatpont a mad√°r sz√°mhoz ({len(daily_7am_data)})")
            return {}

        # Minden napra: el≈ëz≈ë 7:00 - jelenlegi 7:00 = EL≈êZ≈ê NAP fogyaszt√°sa
        for i in range(1, len(daily_7am_data)):
            prev_timestamp, prev_weight, prev_day, _ = daily_7am_data[i-1]
            curr_timestamp, curr_weight, curr_day, _ = daily_7am_data[i]

            # Napi fogyaszt√°s (ez az EL≈êZ≈ê NAP fogyaszt√°sa!)
            daily_consumption_kg = prev_weight - curr_weight

            if daily_consumption_kg < 0:  # Negat√≠v fogyaszt√°s (hib√°s adat vagy felt√∂lt√©s maradt)
                logger.debug(f"‚ö†Ô∏è [{self.sensor_name}] {prev_day}. nap: negat√≠v fogyaszt√°s ({daily_consumption_kg:.1f} kg), kihagyva")
                continue

            if daily_consumption_kg < 10:  # T√∫l kicsi fogyaszt√°s (< 10 kg/nap)
                logger.debug(f"‚ö†Ô∏è [{self.sensor_name}] {prev_day}. nap: t√∫l kicsi fogyaszt√°s ({daily_consumption_kg:.1f} kg), kihagyva")
                continue

            # FONTOS: EL≈êZ≈ê NAP tech adat√°t haszn√°ljuk (mert az a nap fogyott!)
            expected_per_bird_g = self.tech_data.get_daily_intake_per_bird(prev_day)

            if expected_per_bird_g <= 0:
                logger.debug(f"‚ö†Ô∏è [{self.sensor_name}] {prev_day}. nap: nincs tech adat (0 g/mad√°r)")
                continue

            # Mad√°r darabsz√°m kalkul√°ci√≥
            actual_consumption_g = daily_consumption_kg * 1000
            bird_count = int(actual_consumption_g / expected_per_bird_g)

            # EL≈êZ≈ê NAPHOZ rendelj√ºk!
            bird_counts[prev_day] = bird_count

            logger.debug(f"üìä [{self.sensor_name}] {prev_day}. nap: {daily_consumption_kg:.1f} kg fogyaszt√°s, "
                        f"{expected_per_bird_g:.1f} g/mad√°r ‚Üí {bird_count} mad√°r")

        if bird_counts:
            avg_birds = int(np.mean(list(bird_counts.values())))
            logger.info(f"üêî [{self.sensor_name}] Mad√°r darabsz√°m: {min(bird_counts.values())}-{max(bird_counts.values())} "
                       f"(√°tlag: {avg_birds})")

        return bird_counts

    def calculate_correction_factor(self, continuous_data: List[Tuple[datetime, float, int, float]],
                                    bird_counts: Dict[int, int]) -> float:
        """
        Korrekci√≥s szorz√≥ sz√°m√≠t√°sa: val√≥s fogy√°s vs. technol√≥giai fogy√°s ar√°nya

        Ez megmutatja, hogy a val√≥s√°gban h√°ny %-kal fogy t√∂bb/kevesebb takarm√°ny,
        mint amit a technol√≥giai adatok alapj√°n v√°rn√°nk.

        Args:
            continuous_data: Normaliz√°lt adatok (6 √≥r√°nk√©nt)
            bird_counts: Napi mad√°r darabsz√°mok

        Returns:
            correction_factor:
                - 1.00 = pontos egyez√©s (100%)
                - 1.05 = 5%-kal T√ñBB fogy a val√≥s√°gban
                - 0.95 = 5%-kal KEVESEBB fogy a val√≥s√°gban
        """
        if not continuous_data or not bird_counts or len(continuous_data) < 2:
            return 1.0  # Alap√©rtelmezett: nincs korrekci√≥

        total_actual_consumption = 0.0
        total_expected_consumption = 0.0

        # Csak 7:00-as adatpontokat haszn√°lunk napi √∂sszehasonl√≠t√°shoz
        daily_7am_data = [(ts, w, day, exact) for ts, w, day, exact in continuous_data if ts.hour == 7]

        # V√©gigmegy√ºnk minden napon, ahol van bird_count
        for i in range(1, len(daily_7am_data)):
            prev_timestamp, prev_weight, prev_day, _ = daily_7am_data[i-1]
            curr_timestamp, curr_weight, curr_day, _ = daily_7am_data[i]

            # Csak azokat a napokat n√©zz√ºk, ahol van mad√°r sz√°m
            if prev_day not in bird_counts:
                continue

            # Val√≥s fogyaszt√°s (m√©rt)
            actual_consumption_kg = prev_weight - curr_weight

            if actual_consumption_kg < 0:  # Hib√°s adat
                continue

            # V√°rhat√≥ fogyaszt√°s (tech adat)
            bird_count = bird_counts[prev_day]
            expected_per_bird_g = self.tech_data.get_daily_intake_per_bird(prev_day)

            if expected_per_bird_g <= 0:
                continue

            expected_consumption_kg = (expected_per_bird_g * bird_count) / 1000.0

            # Hozz√°adjuk az √∂sszegekhez
            total_actual_consumption += actual_consumption_kg
            total_expected_consumption += expected_consumption_kg

        # Korrekci√≥s szorz√≥ sz√°m√≠t√°sa
        if total_expected_consumption > 0:
            correction_factor = total_actual_consumption / total_expected_consumption
        else:
            correction_factor = 1.0  # Alap√©rtelmezett

        logger.info(f"üìê [{self.sensor_name}] Korrekci√≥s szorz√≥: {correction_factor:.3f} "
                   f"(val√≥s: {total_actual_consumption:.0f} kg, v√°rhat√≥: {total_expected_consumption:.0f} kg)")

        return correction_factor

    def calculate_prediction_with_tech_data(self, continuous_data: List[Tuple[datetime, float, int, float]],
                                           bird_counts: Dict[int, int],
                                           current_real_weight: float) -> Optional[Dict]:
        """
        El≈ërejelz√©s k√©sz√≠t√©se technol√≥giai adatok alapj√°n

        FONTOS: A normaliz√°lt g√∂rbe csak a mad√°r darabsz√°m √©s korrekci√≥s szorz√≥ sz√°m√≠t√°s√°hoz
        haszn√°latos! Az el≈ërejelz√©s a JELENLEGI VAL√ìS S√öLYB√ìL indul!

        Args:
            continuous_data: Normaliz√°lt adatok (timestamp, weight, day, exact_day) - CSAK anal√≠zishez! (6 √≥r√°nk√©nt)
            bird_counts: Napi mad√°r darabsz√°mok
            current_real_weight: VAL√ìS jelenlegi s√∫ly (nem normaliz√°lt!)

        Returns:
            Prediction dictionary vagy None
        """
        if not continuous_data or not bird_counts:
            logger.warning(f"‚ùå [{self.sensor_name}] Nincs el√©g adat az el≈ërejelz√©shez")
            return None

        # Aktu√°lis √°llapot (VAL√ìS s√∫llyal!)
        current_timestamp, _, current_day, _ = continuous_data[-1]

        if current_real_weight <= 0:
            logger.info(f"‚ö†Ô∏è [{self.sensor_name}] A sil√≥ m√°r √ºres (0 kg)")
            return {
                'prediction_date': None,
                'days_until_empty': 0,
                'current_weight': 0,
                'bird_count': bird_counts.get(current_day, 0),
                'day_in_cycle': current_day,
                'status': 'empty'
            }

        # √Åtlagos mad√°r darabsz√°m (utols√≥ 7 nap vagy √∂sszes)
        recent_days = [d for d in bird_counts.keys() if d >= current_day - 7]
        if recent_days:
            avg_bird_count = int(np.mean([bird_counts[d] for d in recent_days]))
        else:
            avg_bird_count = int(np.mean(list(bird_counts.values())))

        logger.info(f"üêî [{self.sensor_name}] √Åtlagos mad√°r darabsz√°m (el≈ërejelz√©shez): {avg_bird_count}")

        # Korrekci√≥s szorz√≥ sz√°m√≠t√°sa (val√≥s vs. tech fogy√°s)
        correction_factor = self.calculate_correction_factor(continuous_data, bird_counts)

        # Iterat√≠v szimul√°ci√≥: VAL√ìS jelenlegi s√∫lyb√≥l indulunk!
        weight = current_real_weight
        day = current_day
        hours_elapsed = 0
        max_days = 100  # Maximum 100 nap el≈ërejelz√©s

        logger.info(f"üéØ [{self.sensor_name}] El≈ërejelz√©s ind√≠t√°sa: "
                   f"val√≥s s√∫ly={weight:.0f} kg, {day}. nap")

        while weight > 0 and day < current_day + max_days:
            # V√°rhat√≥ napi fogyaszt√°s (1 mad√°r, tech adat)
            expected_per_bird_g = self.tech_data.get_daily_intake_per_bird(day)

            # Teljes √°llom√°ny napi fogyaszt√°sa (tech szerint)
            total_daily_kg = (expected_per_bird_g * avg_bird_count) / 1000.0

            # KORREKCI√ì: val√≥s vs. tech ar√°ny alapj√°n
            corrected_daily_kg = total_daily_kg * correction_factor

            # √ìr√°nk√©nti fogyaszt√°s (korrig√°lt)
            hourly_kg = corrected_daily_kg / 24.0

            # S√∫ly cs√∂kkent√©se (1 √≥ra)
            weight -= hourly_kg
            hours_elapsed += 1

            # Nap v√°lt√°s minden 24 √≥r√°ban
            if hours_elapsed % 24 == 0:
                day += 1

            # Debug log minden 7 napban
            if hours_elapsed % (24 * 7) == 0:
                logger.debug(f"   {hours_elapsed}h ({day}. nap): s√∫ly={weight:.0f} kg, "
                           f"tech={total_daily_kg:.1f} kg/nap, korrig√°lt={corrected_daily_kg:.1f} kg/nap")

        prediction_datetime = datetime.now(LOCAL_TZ) + timedelta(hours=hours_elapsed)
        days_until = hours_elapsed / 24.0

        # Form√°zott d√°tum id≈ëablakkal
        formatted_date, window_midpoint_hours = self._format_prediction_with_window(prediction_datetime)
        days_until_midpoint = window_midpoint_hours / 24.0

        logger.info(f"üìÖ [{self.sensor_name}] 0 kg el≈ërejelz√©s: {formatted_date}")
        logger.info(f"‚è±Ô∏è [{self.sensor_name}] H√°tral√©v≈ë id≈ë: {days_until_midpoint:.1f} nap")

        return {
            'prediction_date': formatted_date,
            'days_until_empty': round(days_until_midpoint, 2),
            'current_weight': round(current_real_weight, 0),
            'bird_count': avg_bird_count,
            'day_in_cycle': current_day,
            'correction_factor': round(correction_factor, 3),
            'status': 'emptying',
            'tech_data_used': True
        }

    def resample_5min(self, start_time: datetime, end_time: datetime) -> List[Tuple[datetime, float]]:
        """
        5 perces mintav√©telez√©s CSAK felt√∂lt√©s detekt√°l√°shoz

        NEM haszn√°ljuk predikci√≥s g√∂rb√©hez!

        Args:
            start_time: Kezd≈ë id≈ëpont
            end_time: V√©g id≈ëpont

        Returns:
            [(timestamp, weight), ...] 5 percenk√©nt
        """
        url = f"{self.ha_url}/api/history/period/{start_time.isoformat()}"
        params = {
            'filter_entity_id': self.entity_id,
            'end_time': end_time.isoformat()
        }

        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()
            history = response.json()
        except Exception as e:
            logger.error(f"‚ùå [{self.sensor_name}] 5min resample API hiba: {e}")
            return []

        if not history or len(history) == 0:
            return []

        # √ñsszes adat
        all_data = []
        for record in history[0]:
            try:
                state = record.get('state')
                if state in ['unavailable', 'unknown', 'None', None, '']:
                    continue

                weight = float(state)
                last_changed = record.get('last_changed')
                timestamp = datetime.fromisoformat(last_changed.replace('Z', '+00:00'))
                all_data.append((timestamp, weight))
            except (ValueError, TypeError, AttributeError):
                continue

        if not all_data:
            return []

        # 5 perces mintav√©telez√©s
        all_data.sort(key=lambda x: x[0])
        timestamps = np.array([t for t, _ in all_data])
        weights = np.array([w for _, w in all_data])

        resampled = []
        current = start_time.replace(second=0, microsecond=0)
        current = current.replace(minute=(current.minute // 5) * 5)  # 5 perces kerek√≠t√©s

        while current <= end_time:
            window_start = current - timedelta(minutes=2.5)
            window_end = current + timedelta(minutes=2.5)

            mask = (timestamps >= window_start) & (timestamps <= window_end)
            if np.any(mask):
                avg_weight = np.mean(weights[mask])
                resampled.append((current, avg_weight))

            current += timedelta(minutes=5)

        return resampled

    def detect_refill_completion(self, data_5min: List[Tuple[datetime, float]]) -> Tuple[bool, Optional[datetime]]:
        """
        Felt√∂lt√©s befejez√©s detekt√°l√°s

        Ha 10 percig (2x5 perc) nincs 100kg+ emelked√©s ‚Üí v√©ge

        Args:
            data_5min: 5 perces mintav√©telezett adatok

        Returns:
            (refill_in_progress, refill_end_time)
        """
        if len(data_5min) < 3:
            return False, None

        # Utols√≥ 30 perc adatai (6x5 perc)
        recent = data_5min[-6:]

        # Keress√ºk az utols√≥ jelent≈ës emelked√©st (100kg+)
        last_increase_idx = -1
        for i in range(1, len(recent)):
            weight_change = recent[i][1] - recent[i-1][1]
            if weight_change > 100:  # 100kg+ emelked√©s
                last_increase_idx = i

        # Ha nincs emelked√©s az utols√≥ 30 percben ‚Üí nincs felt√∂lt√©s
        if last_increase_idx == -1:
            return False, None

        # Ha az utols√≥ emelked√©s 10+ perce volt ‚Üí felt√∂lt√©s v√©ge
        time_since_last = len(recent) - 1 - last_increase_idx
        if time_since_last >= 2:  # 2x5 perc = 10 perc
            refill_end_time = recent[last_increase_idx][0]
            return False, refill_end_time

        # Felt√∂lt√©s folyamatban
        return True, None

    def check_active_refill(self) -> Tuple[bool, Optional[datetime], Optional[float]]:
        """
        Ellen≈ërzi, hogy most folyik-e akt√≠v felt√∂lt√©s (5 perces mintav√©telez√©ssel)

        Returns:
            (is_refilling, refill_end_time, current_weight)
        """
        now = datetime.now(LOCAL_TZ)
        start_time = now - timedelta(minutes=30)  # Utols√≥ 30 perc

        # 5 perces mintav√©telez√©s
        data_5min = self.resample_5min(start_time, now)

        if not data_5min:
            return False, None, None

        current_weight = data_5min[-1][1]

        # Felt√∂lt√©s detekt√°l√°s
        is_refilling, refill_end = self.detect_refill_completion(data_5min)

        if is_refilling:
            logger.info(f"üîÑ [{self.sensor_name}] AKT√çV FELT√ñLT√âS FOLYAMATBAN")
            return True, None, current_weight

        if refill_end:
            logger.info(f"‚úÖ [{self.sensor_name}] Felt√∂lt√©s befejezve: {refill_end.strftime('%Y-%m-%d %H:%M')}")
            return False, refill_end, current_weight

        return False, None, current_weight

    def calculate_exp_constant(self, normalized_curve: List[Tuple[datetime, float]]) -> Tuple[float, float, float]:
        """
        Exponenci√°lis √°lland√≥ sz√°m√≠t√°sa normaliz√°lt g√∂rb√©b≈ël

        24 √≥r√°s ablakokb√≥l (4x6h adatpont) napi fogy√°si r√°t√°kat sz√°mol,
        majd line√°ris regresszi√≥val meghat√°rozza a gyorsul√°st.

        Args:
            normalized_curve: [(timestamp, normalized_weight), ...] 6 √≥r√°nk√©nt

        Returns:
            (exp_constant, base_rate, acceleration)
        """
        if len(normalized_curve) < 8:  # Min 2 nap x 4 adatpont
            logger.warning(f"‚ùå [{self.sensor_name}] Exp √°lland√≥: kev√©s adat ({len(normalized_curve)} pont)")
            return 0.0, 0.0, 0.0

        # Napi fogy√°si r√°t√°k sz√°m√≠t√°sa 24 √≥r√°s ablakokb√≥l
        daily_rates = []
        days = []

        for i in range(4, len(normalized_curve)):  # 4 pont = 24 √≥ra
            prev_time, prev_weight = normalized_curve[i-4]
            curr_time, curr_weight = normalized_curve[i]

            # Napi fogy√°s (lehet negat√≠v a normaliz√°lt g√∂rb√©ben!)
            daily_consumption = prev_weight - curr_weight
            if daily_consumption < 0:
                daily_consumption = abs(daily_consumption)

            # Csak √©rtelmes fogy√°sokat vegy√ºk figyelembe
            if daily_consumption > 10:  # Min 10 kg/nap
                daily_rates.append(daily_consumption)
                days.append(i / 4.0)  # Nap index (4 adatpont = 1 nap)

        if len(daily_rates) < 3:
            logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Exp √°lland√≥: kev√©s napi adat ({len(daily_rates)})")
            return 0.0, 0.0, 0.0

        # Line√°ris regresszi√≥: fogy√°si r√°ta v√°ltoz√°sa az id≈ëben
        rates_array = np.array(daily_rates)
        days_array = np.array(days)

        slope, intercept, r_value, _, _ = stats.linregress(days_array, rates_array)

        # Exponenci√°lis √°lland√≥ = gyorsul√°s / √°tlag r√°ta
        avg_rate = np.mean(rates_array)
        exp_constant = slope / avg_rate if avg_rate > 0 else 0.0

        logger.info(f"üìà [{self.sensor_name}] Exp √°lland√≥: {exp_constant:.6f}, "
                   f"alap r√°ta: {avg_rate:.1f} kg/nap, gyorsul√°s: {slope:.2f} kg/nap¬≤")

        return exp_constant, avg_rate, slope

    def predict_with_tech_and_exp(self, current_real_weight: float, cycle_start: datetime,
                                   bird_count: int, base_rate: float, acceleration: float) -> Tuple[datetime, float]:
        """
        ELS≈êDLEGES: Tech adat + Exponenci√°lis predikci√≥ (VAN 0. nap)

        Iterat√≠v szimul√°ci√≥:
        - Tech napi fogyaszt√°s (mad√°rsz√°m √ó tech g/nap)
        - Exponenci√°lis korrekci√≥ (gyorsul√°s figyelembev√©tel√©vel)
        - Val√≥s jelenlegi s√∫lyb√≥l indul

        Args:
            current_real_weight: Jelenlegi val√≥s s√∫ly (kg)
            cycle_start: 0. nap id≈ëpontja
            bird_count: Mad√°rsz√°m
            base_rate: Alap fogy√°si r√°ta (kg/nap)
            acceleration: Gyorsul√°s (kg/nap¬≤)

        Returns:
            (prediction_datetime, days_until)
        """
        weight = current_real_weight
        current_time = datetime.now(LOCAL_TZ)

        # Jelenlegi nevel√©si nap
        current_day = (current_time - cycle_start).days

        hours = 0
        day = current_day
        max_days = 60  # Max 60 nap el≈ëre

        logger.info(f"üéØ [{self.sensor_name}] Tech+Exp predikci√≥: s√∫ly={weight:.0f} kg, "
                   f"nap={day}, mad√°r={bird_count:,}")

        while weight > 0 and day < current_day + max_days:
            # Tech adat: g/mad√°r/nap
            tech_per_bird_g = self.tech_data.get_daily_intake_per_bird(day)
            tech_daily_kg = (tech_per_bird_g * bird_count) / 1000.0

            # Exponenci√°lis korrekci√≥
            days_elapsed = day - current_day
            current_rate = base_rate + (acceleration * days_elapsed)
            exp_factor = current_rate / base_rate if base_rate > 0 else 1.0

            # Korrig√°lt napi fogy√°s
            actual_daily_kg = tech_daily_kg * exp_factor

            # √ìr√°nk√©nti fogy√°s
            hourly_kg = actual_daily_kg / 24.0
            weight -= hourly_kg
            hours += 1

            if hours % 24 == 0:
                day += 1

        prediction_time = current_time + timedelta(hours=hours)
        days_until = hours / 24.0

        logger.info(f"üìÖ [{self.sensor_name}] Tech+Exp: {prediction_time.strftime('%b %d, %H:%M')} "
                   f"({days_until:.1f} nap)")

        return prediction_time, days_until

    def predict_with_exp_only(self, current_real_weight: float, normalized_curve: List[Tuple[datetime, float]],
                               base_rate: float, acceleration: float) -> Tuple[datetime, float]:
        """
        FALLBACK: Csak exponenci√°lis predikci√≥ (NINCS 0. nap)

        Gyorsul√≥ line√°ris extrapol√°ci√≥ a t√∂rt√©nelmi adatokb√≥l.

        Args:
            current_real_weight: Jelenlegi val√≥s s√∫ly (kg)
            normalized_curve: Normaliz√°lt g√∂rbe
            base_rate: Alap fogy√°si r√°ta (kg/nap)
            acceleration: Gyorsul√°s (kg/nap¬≤)

        Returns:
            (prediction_datetime, days_until)
        """
        weight = current_real_weight
        current_time = datetime.now(LOCAL_TZ)

        hours = 0
        current_rate = base_rate
        max_days = 60

        logger.info(f"üéØ [{self.sensor_name}] Exp-only predikci√≥: s√∫ly={weight:.0f} kg, "
                   f"r√°ta={base_rate:.1f} kg/nap, gyorsul√°s={acceleration:.2f}")

        while weight > 0 and hours < (max_days * 24):
            # Napi fogy√°s (gyorsul√≥)
            daily_kg = current_rate
            hourly_kg = daily_kg / 24.0

            weight -= hourly_kg
            hours += 1

            # Naponta n√∂velj√ºk a r√°t√°t a gyorsul√°ssal
            if hours % 24 == 0:
                current_rate += acceleration

        prediction_time = current_time + timedelta(hours=hours)
        days_until = hours / 24.0

        logger.info(f"üìÖ [{self.sensor_name}] Exp-only: {prediction_time.strftime('%b %d, %H:%M')} "
                   f"({days_until:.1f} nap)")

        return prediction_time, days_until

    def calculate_prediction_exponential_fallback(self, data: List[Tuple[datetime, float]]) -> Optional[Dict]:
        """
        FALLBACK M√ìDSZER: Exponenci√°lis regresszi√≥s el≈ërejelz√©s

        Akkor haszn√°latos, ha a 0. nap nem detekt√°lhat√≥ (nincs csend peri√≥dus + felt√∂lt√©s).
        Csak az UTOLS√ì FELT√ñLT√âS UT√ÅNI adatokra √©p√≠t line√°ris regresszi√≥t.

        Args:
            data: Napi mintav√©telezett adatok (timestamp, weight)

        Returns:
            Prediction dictionary vagy None
        """
        if not data or len(data) < 3:
            logger.warning(f"‚ùå [{self.sensor_name}] Exponenci√°lis fallback: kev√©s adat ({len(data)} nap)")
            return None

        # 1. Utols√≥ felt√∂lt√©s keres√©se
        last_refill_index = -1
        for i in range(1, len(data)):
            weight_change = data[i][1] - data[i-1][1]
            if weight_change > 3000:  # Felt√∂lt√©s
                last_refill_index = i

        # 2. Csak utols√≥ felt√∂lt√©s ut√°ni adatok
        if last_refill_index > 0:
            cleaned_data = data[last_refill_index:]
            logger.info(f"üìä [{self.sensor_name}] Exponenci√°lis m√≥dszer: utols√≥ felt√∂lt√©s ut√°ni {len(cleaned_data)} adatpont")

            # Ha kev√©s adat van felt√∂lt√©s ut√°n, haszn√°ljunk MINDEN adatot
            if len(cleaned_data) < 3:
                logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Kev√©s adat felt √∂lt√©s ut√°n ({len(cleaned_data)}), MINDEN adat haszn√°lata...")
                cleaned_data = data
        else:
            cleaned_data = data
            logger.info(f"üìä [{self.sensor_name}] Exponenci√°lis m√≥dszer: {len(cleaned_data)} adatpont (nincs felt√∂lt√©s)")

        if len(cleaned_data) < 3:
            logger.warning(f"‚ùå [{self.sensor_name}] Exponenci√°lis fallback: kev√©s adat √∂sszesen ({len(cleaned_data)})")
            return None

        # 3. Line√°ris regresszi√≥ (s√∫ly ~ id≈ë)
        timestamps = np.array([(t - cleaned_data[0][0]).total_seconds() / 3600 for t, _ in cleaned_data])
        weights = np.array([w for _, w in cleaned_data])

        # Line√°ris illeszt√©s
        slope, intercept, r_value, p_value, std_err = stats.linregress(timestamps, weights)
        r_squared = r_value ** 2

        logger.info(f"üìâ [{self.sensor_name}] Line√°ris regresszi√≥: "
                   f"meredeks√©g={slope:.2f} kg/√≥ra, R¬≤={r_squared:.3f}")

        # 4. El≈ërejelz√©s: mikor lesz 0 kg?
        current_weight = weights[-1]
        current_timestamp = cleaned_data[-1][0]

        if slope >= 0:
            logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Exponenci√°lis fallback: nem cs√∂kken≈ë trend (slope={slope:.2f})")
            return None

        # 0 kg id≈ëpont sz√°m√≠t√°sa: 0 = slope * t + intercept ‚Üí t = -intercept / slope
        current_hours = timestamps[-1]
        hours_until_empty = -current_weight / slope  # H√°ny √≥ra m√∫lva lesz 0 kg

        if hours_until_empty < 0:
            logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Exponenci√°lis fallback: negat√≠v el≈ërejelz√©s")
            return None

        prediction_datetime = datetime.now(LOCAL_TZ) + timedelta(hours=hours_until_empty)
        days_until = hours_until_empty / 24.0

        # Form√°zott d√°tum
        formatted_date, window_midpoint_hours = self._format_prediction_with_window(prediction_datetime)
        days_until_midpoint = window_midpoint_hours / 24.0

        logger.info(f"üìÖ [{self.sensor_name}] Exponenci√°lis fallback 0 kg: {formatted_date}")
        logger.info(f"‚è±Ô∏è [{self.sensor_name}] H√°tral√©v≈ë id≈ë: {days_until_midpoint:.1f} nap")

        return {
            'prediction_date': formatted_date,
            'days_until_empty': round(days_until_midpoint, 2),
            'current_weight': round(current_weight, 0),
            'bird_count': None,  # Nem tudjuk
            'day_in_cycle': None,  # Nem tudjuk
            'correction_factor': None,
            'status': 'emptying',
            'tech_data_used': False,
            'method': 'exponential_fallback',
            'r_squared': round(r_squared, 3)
        }

    def calculate_prediction(self, data: List[Tuple[datetime, float]],
                             last_refill_time: Optional[datetime] = None) -> Optional[Dict]:
        """
        El≈ërejelz√©s k√©sz√≠t√©se line√°ris regresszi√≥val (opcion√°lis n√∂veked√©si korrekci√≥val)

        ‚ö†Ô∏è EZ A R√âGI M√ìDSZER - MOSTANT√ìL NEM HASZN√ÅLT!

        Args:
            data: S√∫ly adatok (timestamp, weight) p√°rok
            last_refill_time: Utols√≥ felt√∂lt√©s id≈ëpontja (None ha nem volt)

        Returns:
            Prediction dictionary vagy None
        """

        # Ellen≈ërizz√ºk, hogy √©ppen most van-e felt√∂lt√©s (utols√≥ 15 percben)
        if last_refill_time:
            time_since_refill = (datetime.now(LOCAL_TZ) - last_refill_time).total_seconds() / 3600
            if time_since_refill < 0.25:  # 15 perc = 0.25 √≥ra
                minutes_since = int(time_since_refill * 60)
                logger.info(f"üîÑ [{self.sensor_name}] Felt√∂lt√©s folyamatban ({minutes_since} perce)")
                return {
                    'prediction_date': None,
                    'days_until_empty': None,
                    'slope': None,
                    'r_squared': None,
                    'current_weight': data[-1][1] if data else None,
                    'threshold': 0,
                    'status': 'refilling',
                    'refill_message': f'Felt√∂lt√©s alatt ({minutes_since} perce)'
                }

        # AZONNALI el≈ërejelz√©s 15 perc ut√°n (ha van el≈ëz≈ë slope)
        # 3 √≥r√°s mintav√©telez√©sn√©l: minimum 8 adatpont (24 √≥ra) kell az √∫j regresszi√≥hoz
        use_previous_slope = False
        if len(data) < 8:  # 8 * 3 √≥ra = 24 √≥ra
            if self.previous_slope is not None:
                logger.info(f"‚ö° [{self.sensor_name}] Felt√∂lt√©s ut√°ni azonnali el≈ërejelz√©s! "
                           f"({len(data)} adatpont, el≈ëz≈ë slope: {self.previous_slope:.4f} kg/√≥ra)")
                use_previous_slope = True
            else:
                logger.warning(f"‚è≥ [{self.sensor_name}] Adatra v√°r "
                             f"(minimum 8 adatpont vagy el≈ëz≈ë slope kell, {len(data)} van)")
                return {
                    'prediction_date': None,
                    'days_until_empty': None,
                    'slope': None,
                    'r_squared': None,
                    'current_weight': data[-1][1] if data else None,
                    'threshold': 0,
                    'status': 'waiting_for_data',
                    'message': 'Adatra v√°r'
                }

        timestamps = [t for t, w in data]
        weights = [w for t, w in data]

        start_time = timestamps[0]
        hours = [(t - start_time).total_seconds() / 3600 for t in timestamps]

        # Slope meghat√°roz√°sa
        if use_previous_slope:
            # Haszn√°ljuk az el≈ëz≈ë ciklus slope-j√°t
            slope = self.previous_slope
            r_squared = self.previous_r_squared if self.previous_r_squared else 0.95

            # Intercept becsl√©se a jelenlegi adatokb√≥l
            # intercept = weight - slope * hours
            intercept = weights[-1] - slope * hours[-1]

            logger.info(f"üìâ [{self.sensor_name}] El≈ëz≈ë ciklus slope haszn√°lata: meredeks√©g={slope:.2f} kg/√≥ra, R¬≤={r_squared:.4f}")
        else:
            # Norm√°l regresszi√≥
            slope, intercept, r_value, p_value, std_err = stats.linregress(hours, weights)
            r_squared = r_value ** 2

            # Mentj√ºk el a slope-ot a k√∂vetkez≈ë ciklushoz
            if r_squared > 0.7:  # Csak j√≥ min≈ës√©g≈± slope-ot ment√ºnk
                self._save_current_slope(slope, r_squared)

            logger.info(f"üìâ [{self.sensor_name}] Regresszi√≥: meredeks√©g={slope:.2f} kg/√≥ra, R¬≤={r_squared:.4f}")

        current_hours = hours[-1]
        current_weight = weights[-1]

        if abs(slope) < 0.01:
            logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] K√∂zel nulla meredeks√©g, nincs trend")
            return {
                'prediction_date': None,
                'days_until_empty': None,
                'slope': slope,
                'r_squared': r_squared,
                'current_weight': current_weight,
                'status': 'no_trend'
            }

        if slope >= -0.1:
            logger.info(f"‚ö†Ô∏è [{self.sensor_name}] A sil√≥ nem √ºr√ºl (pozit√≠v vagy nulla trend)")
            return {
                'prediction_date': None,
                'days_until_empty': None,
                'slope': slope,
                'r_squared': r_squared,
                'current_weight': current_weight,
                'threshold': 0,
                'status': 'filling' if slope > 0 else 'stable'
            }

        # N√∂veked√©si korrekci√≥ alkalmaz√°sa
        if self.enable_growth_correction:
            hours_from_now = self._calculate_with_growth_correction(
                current_weight, slope, current_hours, self.animal_age_days
            )
            logger.info(f"üå± [{self.sensor_name}] N√∂veked√©si korrekci√≥ alkalmazva: {hours_from_now:.1f} √≥ra")
        else:
            # Eredeti line√°ris sz√°m√≠t√°s
            hours_to_zero = -intercept / slope
            hours_from_now = hours_to_zero - current_hours

        if hours_from_now < 0:
            logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] A sz√°m√≠t√°s szerint m√°r ki√ºr√ºlt volna (hib√°s adat)")
            return {
                'prediction_date': None,
                'days_until_empty': None,
                'slope': slope,
                'r_squared': r_squared,
                'current_weight': current_weight,
                'threshold': 0,
                'status': 'error'
            }

        days_until = hours_from_now / 24

        if days_until > 365:
            logger.info(f"‚ö†Ô∏è [{self.sensor_name}] T√∫l t√°voli el≈ërejelz√©s: {days_until:.0f} nap")
            return {
                'prediction_date': None,
                'days_until_empty': None,
                'slope': slope,
                'r_squared': r_squared,
                'current_weight': current_weight,
                'threshold': 0,
                'status': 'too_far'
            }

        # El≈ërejelz√©s lok√°lis id≈ëben
        prediction_datetime = datetime.now(LOCAL_TZ) + timedelta(hours=hours_from_now)

        # Form√°zott d√°tum id≈ëablakkal (¬±1 √≥ra)
        formatted_date, window_midpoint_hours = self._format_prediction_with_window(prediction_datetime)

        # H√°tral√©v≈ë id≈ë az id≈ëablak K√ñZEP√âIG (nem a pontos id≈ëig!)
        days_until_midpoint = window_midpoint_hours / 24

        logger.info(f"üìÖ [{self.sensor_name}] 0 kg el≈ërejelz√©s: {formatted_date}")
        logger.info(f"‚è±Ô∏è [{self.sensor_name}] H√°tral√©v≈ë id≈ë (ablak k√∂zep√©ig): {days_until_midpoint:.1f} nap")

        return {
            'prediction_date': formatted_date,
            'days_until_empty': round(days_until_midpoint, 2),
            'slope': round(slope, 2),
            'r_squared': round(r_squared, 4),
            'current_weight': round(current_weight, 0),
            'threshold': 0,
            'status': 'emptying',
            'growth_correction_enabled': self.enable_growth_correction
        }

    def _format_prediction_with_window(self, prediction_datetime: datetime) -> Tuple[str, float]:
        """
        Form√°zza az el≈ërejelz√©st id≈ëablakkal (¬±1 √≥ra, kerek√≠tve)

        Form√°tum:
        - Ma 16-18 √≥ra k√∂z√∂tt (~17:45)
        - Holnap 10-12 √≥ra k√∂z√∂tt (~11:30)
        - 2025-12-15 16-18 √≥ra k√∂z√∂tt (~17:20)

        Logika: prediction_datetime ¬± 1 √≥ra, kerek√≠tve eg√©sz √≥r√°kra

        Args:
            prediction_datetime: El≈ërejelzett id≈ëpont

        Returns:
            Tuple: (formatted_string, hours_until_midpoint)
                   hours_until_midpoint: √ìr√°k sz√°ma az id≈ëablak k√∂zep√©ig
        """
        now = datetime.now(LOCAL_TZ)

        # ¬±1 √≥ra ablak sz√°m√≠t√°sa
        window_start_dt = prediction_datetime - timedelta(hours=1)
        window_end_dt = prediction_datetime + timedelta(hours=1)

        # Kerek√≠t√©s eg√©sz √≥r√°kra
        # Ha perc < 30, lefel√© kerek√≠t√ºnk, k√ºl√∂nben felfel√©
        if window_start_dt.minute < 30:
            hour_start = window_start_dt.hour
        else:
            hour_start = (window_start_dt.hour + 1) % 24

        if window_end_dt.minute < 30:
            hour_end = window_end_dt.hour
        else:
            hour_end = (window_end_dt.hour + 1) % 24

        # Id≈ëablak k√∂z√©ppontja (√≥r√°ban)
        midpoint_hour = (hour_start + hour_end) / 2
        if hour_end < hour_start:  # √âjf√©li √°tl√©p√©s
            midpoint_hour = (hour_start + hour_end + 24) / 2
            if midpoint_hour >= 24:
                midpoint_hour -= 24

        # Id≈ëablak k√∂z√©ppontj√°nak datetime objektuma
        midpoint_date = prediction_datetime.date()
        if hour_end < hour_start and midpoint_hour < 12:  # √âjf√©li √°tl√©p√©s, k√∂z√©ppont m√°r m√°snapra esik
            midpoint_date = (prediction_datetime + timedelta(days=1)).date()

        window_midpoint = datetime.combine(midpoint_date, datetime.min.time()).replace(
            hour=int(midpoint_hour),
            minute=int((midpoint_hour - int(midpoint_hour)) * 60),
            tzinfo=LOCAL_TZ
        )

        # √ìr√°k sz√°ma a k√∂z√©ppontig
        hours_until_midpoint = (window_midpoint - now).total_seconds() / 3600

        # D√°tum k√ºl√∂nbs√©g napokban
        days_diff = (prediction_datetime.date() - now.date()).days

        # Relat√≠v d√°tum form√°z√°s
        if days_diff == 0:
            date_str = "Ma"
        elif days_diff == 1:
            date_str = "Holnap"
        elif days_diff == 2:
            date_str = "Holnaput√°n"
        else:
            date_str = prediction_datetime.strftime('%Y-%m-%d')

        # Pontos id≈ë z√°r√≥jelben
        exact_time = prediction_datetime.strftime('%H:%M')

        # Id≈ëablak form√°z√°s
        if hour_end > hour_start or (hour_end == 0 and hour_start == 22):  # √âjf√©li √°tl√©p√©s: 22-00
            time_window = f"{hour_start:02d}-{hour_end:02d} √≥ra k√∂z√∂tt (~{exact_time})"
        else:
            # Norm√°l √©jf√©li √°tl√©p√©s
            time_window = f"{hour_start:02d}-{hour_end:02d} √≥ra k√∂z√∂tt (~{exact_time}, √©jf√©li √°tl√©p√©s)"

        return f"{date_str} {time_window}", hours_until_midpoint

    def _calculate_with_growth_correction(self, current_weight: float, base_slope: float,
                                          current_hours: float, animal_age_days: float,
                                          step_hours: int = 3) -> float:
        """
        N√∂veked√©si korrekci√≥s sz√°m√≠t√°s - iterat√≠v megold√°s

        A n√∂vekv≈ë takarm√°nyfogyaszt√°s miatt a sil√≥ gyorsabban √ºr√ºl, mint amit a line√°ris regresszi√≥ mutat.

        Args:
            current_weight: Jelenlegi s√∫ly (kg)
            base_slope: Line√°ris regresszi√≥ meredeks√©ge (kg/√≥ra) - NEGAT√çV!
            current_hours: Eltelt √≥r√°k sz√°ma a m√©r√©si kezdet √≥ta
            animal_age_days: √Ållatok jelenlegi √©letkora napokban
            step_hours: Szimul√°ci√≥s l√©p√©sk√∂z √≥r√°kban (alap√©rtelmezett: 3)

        Returns:
            H√°tral√©v≈ë √≥r√°k sz√°ma a 0 kg el√©r√©s√©ig
        """
        # Iterat√≠v sz√°m√≠t√°s - 3 √≥r√°s l√©p√©sekkel
        weight = current_weight
        hours_elapsed = 0
        max_iterations = 10000 // step_hours  # Maximum ~416 nap (3 √≥r√°s l√©p√©sekkel)

        # Jelenlegi nap
        current_day = animal_age_days

        logger.info(f"üßÆ [{self.sensor_name}] N√∂veked√©si szimul√°ci√≥s sz√°m√≠t√°s ind√≠t√°sa...")
        logger.info(f"   Kezdeti s√∫ly: {current_weight:.1f} kg")
        logger.info(f"   Alapmeredeks√©g: {base_slope:.4f} kg/√≥ra")
        logger.info(f"   √Ållat √©letkor: {animal_age_days:.1f} nap")
        logger.info(f"   Szimul√°ci√≥s l√©p√©sk√∂z: {step_hours} √≥ra")

        iteration = 0
        while weight > 0 and iteration < max_iterations:
            # Aktu√°lis nap (az √°llatok√©hoz k√©pest)
            day_in_cycle = current_day + (hours_elapsed / 24.0)

            # N√∂veked√©si korrekci√≥ az aktu√°lis napra
            growth_adjustment = self.growth_rate_kg_per_hour_per_day * day_in_cycle

            # Teljes √≥r√°nk√©nti fogy√°s (negat√≠v, ez√©rt a growth_adjustment CS√ñKKENTI)
            hourly_consumption = base_slope - growth_adjustment

            # S√∫ly cs√∂kkent√©se (step_hours √≥r√°nyira)
            weight += hourly_consumption * step_hours

            hours_elapsed += step_hours
            iteration += 1

            # Debug log minden 100 iter√°ci√≥nk√©nt (~300 √≥ra)
            if iteration % 100 == 0:
                logger.debug(f"   {hours_elapsed}h: s√∫ly={weight:.1f} kg, "
                           f"napi_poz√≠ci√≥={day_in_cycle:.1f}, korrekci√≥={growth_adjustment:.6f} kg/√≥ra")

        if iteration >= max_iterations:
            logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Szimul√°ci√≥s limit el√©rve ({max_iterations} iter√°ci√≥)")
            return hours_elapsed

        logger.info(f"‚úÖ [{self.sensor_name}] Szimul√°ci√≥s eredm√©ny: {hours_elapsed} √≥ra ({hours_elapsed/24:.1f} nap)")

        return hours_elapsed

    def update_sensor(self, prediction_data: Dict):
        """Home Assistant szenzor friss√≠t√©se"""
        if not prediction_data:
            logger.warning(f"‚ùå [{self.sensor_name}] Nincs el≈ërejelz√©si adat a szenzor friss√≠t√©shez")
            return

        self._update_date_sensor(prediction_data)
        self._update_time_remaining_sensor(prediction_data)
        self._update_bird_count_sensor(prediction_data)
        self._update_last_updated_sensor()

    def _update_date_sensor(self, prediction_data: Dict):
        """D√°tum szenzor friss√≠t√©se (mikor lesz 0 kg)"""
        sensor_entity_id = f"sensor.{self.sensor_name.lower().replace(' ', '_')}"

        prediction_date = prediction_data.get('prediction_date')
        status = prediction_data.get('status', 'unknown')

        # Speci√°lis √ºzenetek
        if status == 'refilling':
            state = "Felt√∂lt√©s alatt"
        elif status == 'waiting_for_data':
            state = "Adatra v√°r"
        else:
            state = prediction_date if prediction_date else status

        attributes = {
            'prediction_date': prediction_date,
            'days_until_empty': prediction_data.get('days_until_empty'),
            'current_weight_kg': prediction_data.get('current_weight'),
            'bird_count': prediction_data.get('bird_count'),
            'day_in_cycle': prediction_data.get('day_in_cycle'),
            'correction_factor': prediction_data.get('correction_factor'),
            'status': status,
            'friendly_name': self.sensor_name,
            'icon': 'mdi:silo',
            # Ciklus adatok ment√©se
            'cycle_start_date': self.cycle_start_date.isoformat() if self.cycle_start_date else None,
            'tech_data_used': prediction_data.get('tech_data_used', False)
        }

        self._post_sensor(sensor_entity_id, state, attributes)

    def _update_time_remaining_sensor(self, prediction_data: Dict):
        """H√°tral√©v≈ë id≈ë szenzor friss√≠t√©se (X nap Y √≥ra form√°tum)"""
        time_sensor_entity_id = f"sensor.{self.sensor_name.lower().replace(' ', '_')}_time_remaining"

        days_until = prediction_data.get('days_until_empty')
        status = prediction_data.get('status', 'unknown')

        if days_until is not None and days_until >= 0:
            days = int(days_until)
            hours = int((days_until - days) * 24)

            if days > 0:
                state = f"{days} nap {hours} √≥ra"
            else:
                state = f"{hours} √≥ra"
        else:
            state = status

        attributes = {
            'days': int(days_until) if days_until is not None else None,
            'hours': int((days_until - int(days_until)) * 24) if days_until is not None else None,
            'total_hours': round(days_until * 24, 1) if days_until is not None else None,
            'status': status,
            'friendly_name': f"{self.sensor_name} - H√°tral√©v≈ë Id≈ë",
            'icon': 'mdi:timer-sand'
        }

        self._post_sensor(time_sensor_entity_id, state, attributes)

    def _update_bird_count_sensor(self, prediction_data: Dict):
        """Mad√°r darabsz√°m szenzor friss√≠t√©se"""
        bird_count_entity_id = f"sensor.{self.sensor_name.lower().replace(' ', '_')}_bird_count"

        bird_count = prediction_data.get('bird_count')
        day_in_cycle = prediction_data.get('day_in_cycle', 0)

        if bird_count is not None:
            state = str(bird_count)
        else:
            state = "unknown"

        attributes = {
            'bird_count': bird_count,
            'day_in_cycle': day_in_cycle,
            'unit_of_measurement': 'mad√°r',
            'friendly_name': f"{self.sensor_name} - Mad√°r Darabsz√°m",
            'icon': 'mdi:bird'
        }

        self._post_sensor(bird_count_entity_id, state, attributes)

    def _update_last_updated_sensor(self):
        """Utols√≥ friss√≠t√©s id≈ëpontja szenzor"""
        last_updated_entity_id = f"sensor.{self.sensor_name.lower().replace(' ', '_')}_last_updated"

        # Aktu√°lis id≈ë lok√°lis id≈ëz√≥n√°ban
        now = datetime.now(LOCAL_TZ)

        # Form√°zott id≈ëb√©lyeg
        timestamp = now.strftime('%Y-%m-%d %H:%M:%S')

        attributes = {
            'timestamp': timestamp,
            'friendly_name': f"{self.sensor_name} - Utols√≥ Friss√≠t√©s",
            'icon': 'mdi:clock-check-outline'
        }

        self._post_sensor(last_updated_entity_id, timestamp, attributes)

    def _post_sensor(self, entity_id: str, state: str, attributes: Dict):
        """K√∂z√∂s met√≥dus szenzor adatok POST-ol√°s√°hoz"""
        url = f"{self.ha_url}/api/states/{entity_id}"
        payload = {
            'state': state,
            'attributes': attributes
        }

        try:
            response = requests.post(url, headers=self.headers, json=payload, timeout=10)
            response.raise_for_status()
            logger.info(f"‚úÖ [{self.sensor_name}] Szenzor friss√≠tve: {entity_id} = {state}")
        except requests.RequestException as e:
            logger.error(f"‚ùå [{self.sensor_name}] Szenzor friss√≠t√©si hiba ({entity_id}): {e}")
            if hasattr(e, 'response') and hasattr(e.response, 'text'):
                logger.error(f"V√°lasz: {e.response.text}")

    def process(self):
        """
        Teljes feldolgoz√°si folyamat egy silohoz

        √öJ LOGIKA:
        1. 45 napos adatok lek√©r√©se
        2. 6 √ìR√ÅNK√âNTI mintav√©telez√©s (7:00, 13:00, 19:00, 1:00) - napi 4 adatpont
        3. AKT√çV FELT√ñLT√âS ELLEN≈êRZ√âS (utols√≥ 3 adatpont vizsg√°lata)
        4. 0. nap (ciklus kezdet) detekt√°l√°s pr√≥b√°lkoz√°s
        5a. HA SIKER√úLT 0. nap detekt√°l√°s:
            - Folyamatos g√∂rbe (normaliz√°lt, 6√≥r√°nk√©nt) ‚Üí mad√°r darabsz√°m + korrekci√≥s szorz√≥
            - El≈ërejelz√©s technol√≥giai adatok + VAL√ìS jelenlegi s√∫ly
        5b. HA NEM SIKER√úLT 0. nap detekt√°l√°s:
            - FALLBACK: Exponenci√°lis regresszi√≥ utols√≥ felt√∂lt√©s ut√°ni adatokra
        6. Szenzor friss√≠t√©se
        """
        try:
            logger.info(f"üîÑ [{self.sensor_name}] Feldolgoz√°s ind√≠t√°sa...")

            # 1. Adatok lek√©r√©se (45 nap)
            raw_data = self.get_historical_data()

            if not raw_data:
                logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Nincs adat")
                return

            # 2. AKT√çV FELT√ñLT√âS ELLEN≈êRZ√âS (5 perces mintav√©telez√©ssel)
            is_refilling, refill_end, current_weight = self.check_active_refill()

            if is_refilling:
                # Felt√∂lt√©s alatt szenzor friss√≠t√©se
                refilling_data = {
                    'prediction_date': 'Felt√∂lt√©s alatt',
                    'days_until_empty': None,
                    'current_weight': current_weight,
                    'bird_count': self.bird_count,
                    'day_in_cycle': None,
                    'status': 'refilling'
                }
                self.update_sensor(refilling_data)
                logger.info(f"‚úÖ [{self.sensor_name}] Felt√∂lt√©s alatt szenzor friss√≠tve")
                return

            # 3. 6 √≥r√°s mintav√©telez√©s (predikci√≥s g√∂rb√©hez)
            daily_data = self.sample_daily_data(raw_data)

            if not daily_data:
                logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Nincs napi mintav√©telezett adat")
                return

            # Jelenlegi VAL√ìS s√∫ly (utols√≥ m√©rt √©rt√©k)
            current_real_weight = daily_data[-1][1]

            # 4. Normaliz√°lt g√∂rbe k√©sz√≠t√©se (csak timestamp, weight p√°rokat haszn√°lunk)
            normalized_simple = [(t, w) for t, w, _, _ in daily_data] if daily_data and len(daily_data[0]) == 4 else daily_data

            # 5. Exponenci√°lis √°lland√≥ sz√°m√≠t√°sa
            exp_constant, base_rate, acceleration = self.calculate_exp_constant(normalized_simple)

            if base_rate == 0:
                logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Nem siker√ºlt exp √°lland√≥t sz√°m√≠tani")
                return

            # 6. 0. nap detekt√°l√°s (ha m√©g nincs)
            cycle_start_detected = False
            if not self.cycle_start_date:
                cycle_start = self.detect_cycle_start(daily_data)
                if cycle_start:
                    self._save_cycle_data(cycle_start, None)  # bird_count k√©s≈ëbb ker√ºl meghat√°roz√°sra
                    cycle_start_detected = True
                else:
                    logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] 0. nap nem detekt√°lhat√≥ ‚Üí Fallback m√≥dszer")
            else:
                cycle_start_detected = True

            # 7. PREDIKCI√ì
            if cycle_start_detected and self.cycle_start_date:
                logger.info(f"‚úÖ [{self.sensor_name}] TECH + EXP M√ìDSZER haszn√°lata")

                # Folyamatos g√∂rbe k√©sz√≠t√©se (mad√°r sz√°m√≠t√°shoz)
                continuous_data = self.create_continuous_curve(daily_data, self.cycle_start_date)

                if not continuous_data:
                    logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Nincs folyamatos g√∂rbe adat")
                    return

                # Mad√°r darabsz√°m kalkul√°ci√≥
                bird_counts = self.calculate_daily_bird_count(continuous_data)

                if not bird_counts:
                    logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] Mad√°r darabsz√°m nem sz√°molhat√≥, fallback...")
                    # Fallback-re v√°ltunk
                    prediction_time, days_until = self.predict_with_exp_only(
                        current_real_weight, normalized_simple, base_rate, acceleration
                    )

                    # Form√°zott d√°tum
                    formatted_date, window_midpoint_hours = self._format_prediction_with_window(prediction_time)
                    days_until_midpoint = window_midpoint_hours / 24.0

                    # Nevel√©si nap (ha van cycle_start_date)
                    current_day = (datetime.now(LOCAL_TZ) - self.cycle_start_date).days if self.cycle_start_date else None

                    prediction = {
                        'prediction_date': formatted_date,
                        'days_until_empty': round(days_until_midpoint, 2),
                        'current_weight': round(current_real_weight, 0),
                        'bird_count': None,
                        'day_in_cycle': current_day,
                        'status': 'emptying',
                        'tech_data_used': False
                    }
                else:
                    # √Åtlag mad√°rsz√°m
                    avg_bird_count = int(np.mean(list(bird_counts.values())))

                    # Tech + Exp predikci√≥
                    prediction_time, days_until = self.predict_with_tech_and_exp(
                        current_real_weight, self.cycle_start_date,
                        avg_bird_count, base_rate, acceleration
                    )

                    # Form√°zott d√°tum
                    formatted_date, window_midpoint_hours = self._format_prediction_with_window(prediction_time)
                    days_until_midpoint = window_midpoint_hours / 24.0

                    # Nevel√©si nap
                    current_day = (datetime.now(LOCAL_TZ) - self.cycle_start_date).days

                    prediction = {
                        'prediction_date': formatted_date,
                        'days_until_empty': round(days_until_midpoint, 2),
                        'current_weight': round(current_real_weight, 0),
                        'bird_count': avg_bird_count,
                        'day_in_cycle': current_day,
                        'status': 'emptying',
                        'tech_data_used': True
                    }

            # 7b. EXPONENCI√ÅLIS FALLBACK M√ìDSZER (ha nincs 0. nap)
            else:
                logger.info(f"‚ö†Ô∏è [{self.sensor_name}] EXP-ONLY FALLBACK M√ìDSZER haszn√°lata")

                # Csak Exp predikci√≥
                prediction_time, days_until = self.predict_with_exp_only(
                    current_real_weight, normalized_simple, base_rate, acceleration
                )

                # Form√°zott d√°tum
                formatted_date, window_midpoint_hours = self._format_prediction_with_window(prediction_time)
                days_until_midpoint = window_midpoint_hours / 24.0

                prediction = {
                    'prediction_date': formatted_date,
                    'days_until_empty': round(days_until_midpoint, 2),
                    'current_weight': round(current_real_weight, 0),
                    'bird_count': None,
                    'day_in_cycle': None,
                    'status': 'emptying',
                    'tech_data_used': False
                }

            # 5. Szenzor friss√≠t√©se
            if prediction:
                # Mentj√ºk a bird_count-ot a ciklus adatok k√∂z√©
                if not self.bird_count and prediction.get('bird_count'):
                    self.bird_count = prediction['bird_count']

                self.update_sensor(prediction)
                logger.info(f"‚úÖ [{self.sensor_name}] Feldolgoz√°s sikeres")
            else:
                logger.warning(f"‚ö†Ô∏è [{self.sensor_name}] El≈ërejelz√©s sikertelen")

        except Exception as e:
            logger.error(f"‚ùå [{self.sensor_name}] Hiba a feldolgoz√°s sor√°n: {e}", exc_info=True)


class MultiSiloManager:
    """Multi-silo manager - kezeli az √∂sszes sil√≥t"""

    def __init__(self):
        self.ha_url = os.getenv('HA_URL', 'http://supervisor/core')
        self.ha_token = os.getenv('HA_TOKEN', os.getenv('SUPERVISOR_TOKEN'))
        self.prediction_days = int(os.getenv('PREDICTION_DAYS', '45'))  # 45 nap az √∫j alap√©rtelmezett
        self.update_interval = int(os.getenv('UPDATE_INTERVAL', '86400'))  # 24 √≥ra (86400s)

        logger.info("üöÄ Multi-Silo Prediction Add-on ind√≠tva")
        logger.info(f"Home Assistant URL: {self.ha_url}")

        if not self.ha_token:
            logger.error("‚ùå SUPERVISOR_TOKEN vagy HA_TOKEN nincs be√°ll√≠tva!")
        else:
            logger.info(f"‚úÖ Token hossza: {len(self.ha_token)} karakter")

        # Sil√≥ konfigur√°ci√≥ bet√∂lt√©se
        self.silos = self._load_silo_config()
        logger.info(f"üì¶ {len(self.silos)} silo konfigur√°lva")

    def _load_silo_config(self) -> List[SiloPredictor]:
        """Sil√≥ konfigur√°ci√≥ bet√∂lt√©se JSON-b√≥l"""
        silos_json = os.getenv('SILOS_CONFIG', '[]')

        try:
            silos_config = json.loads(silos_json)
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Hib√°s JSON konfigur√°ci√≥: {e}")
            return []

        silos = []
        for silo_cfg in silos_config:
            try:
                silo = SiloPredictor(
                    ha_url=self.ha_url,
                    ha_token=self.ha_token,
                    entity_id=silo_cfg['entity_id'],
                    sensor_name=silo_cfg['sensor_name'],
                    refill_threshold=silo_cfg.get('refill_threshold', 1000),
                    max_capacity=silo_cfg.get('max_capacity', 20000),
                    prediction_days=self.prediction_days,
                    tech_csv_path='/app/tech_feed_data.csv'
                )
                silos.append(silo)
            except KeyError as e:
                logger.error(f"‚ùå Hi√°nyz√≥ mez≈ë a silo konfigur√°ci√≥ban: {e}")

        return silos

    def _check_recent_refill(self, silo: 'SiloPredictor') -> bool:
        """
        Ellen≈ërzi, hogy volt-e friss felt√∂lt√©s az elm√∫lt 20 percben

        Args:
            silo: SiloPredictor p√©ld√°ny

        Returns:
            True ha volt friss felt√∂lt√©s (< 20 perc)
        """
        try:
            # Utols√≥ 1 √≥ra adat lek√©r√©se
            end_time = datetime.now(LOCAL_TZ)
            start_time = end_time - timedelta(hours=1)

            url = f"{self.ha_url}/api/history/period/{start_time.isoformat()}"
            params = {
                'filter_entity_id': silo.entity_id,
                'end_time': end_time.isoformat()
            }

            response = requests.get(url, headers=silo.headers, params=params, timeout=10)
            if response.status_code != 200:
                return False

            data = response.json()
            if not data or not data[0]:
                return False

            # Utols√≥ 2 adatpont vizsg√°lata
            recent_data = data[0][-2:] if len(data[0]) >= 2 else data[0]

            for i in range(1, len(recent_data)):
                try:
                    prev_weight = float(recent_data[i-1].get('state', 0))
                    curr_weight = float(recent_data[i].get('state', 0))
                    weight_change = curr_weight - prev_weight

                    timestamp_str = recent_data[i].get('last_changed', '')
                    timestamp_utc = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                    timestamp = timestamp_utc.astimezone(LOCAL_TZ)

                    minutes_ago = (datetime.now(LOCAL_TZ) - timestamp).total_seconds() / 60

                    # Felt√∂lt√©s detekt√°l√°s: +3000 kg az elm√∫lt 20 percben
                    if weight_change > 3000 and minutes_ago < 20:
                        logger.info(f"üîÑ [{silo.sensor_name}] Friss felt√∂lt√©s detekt√°lva: "
                                   f"{minutes_ago:.0f} perce, +{weight_change:.0f} kg")
                        return True

                except (ValueError, KeyError, TypeError):
                    continue

            return False

        except Exception as e:
            logger.debug(f"‚ùå [{silo.sensor_name}] Felt√∂lt√©s ellen≈ërz√©si hiba: {e}")
            return False

    def run(self):
        """
        F≈ë fut√°si ciklus - periodikusan feldolgozza az √∂sszes sil√≥t

        FRISS√çT√âSI LOGIKA:
        - Norm√°l: 24 √≥r√°nk√©nt
        - Felt√∂lt√©s ut√°n: 20 perc v√°rakoz√°s, majd AZONNALI friss√≠t√©s
        """
        # V√°rakoz√°s Home Assistant core fel√°ll√°s√°ra (502 Bad Gateway elker√ºl√©se)
        logger.info("‚è≥ V√°rakoz√°s 30 m√°sodpercet a Home Assistant core indul√°s√°ra...")
        time.sleep(30)

        logger.info("üîÑ Multi-Silo Prediction szolg√°ltat√°s ind√≠tva")
        logger.info(f"üìä Norm√°l friss√≠t√©si intervallum: {self.update_interval / 3600:.0f} √≥ra")
        logger.info(f"‚ö° Felt√∂lt√©s ut√°ni friss√≠t√©s: 20 perc v√°rakoz√°s ut√°n")

        while True:
            try:
                logger.info("=" * 60)
                logger.info(f"üîÑ √öj feldolgoz√°si ciklus kezd≈ëdik ({len(self.silos)} silo)")

                refill_detected = False

                for silo in self.silos:
                    silo.process()

                    # Ellen≈ërizz√ºk, hogy volt-e friss felt√∂lt√©s
                    if self._check_recent_refill(silo):
                        refill_detected = True

                logger.info(f"‚úÖ Feldolgoz√°si ciklus befejezve")

                # Felt√∂lt√©s ut√°ni logika
                if refill_detected:
                    logger.info(f"‚ö° Felt√∂lt√©s detekt√°lva! V√°rakoz√°s 20 perc, majd √∫jra futtat√°s...")
                    time.sleep(20 * 60)  # 20 perc = 1200 m√°sodperc

                    logger.info("üîÑ Felt√∂lt√©s ut√°ni √∫jra futtat√°s...")
                    for silo in self.silos:
                        silo.process()

                    logger.info(f"‚úÖ Felt√∂lt√©s ut√°ni friss√≠t√©s befejezve")

                # Norm√°l v√°rakoz√°s
                logger.info(f"‚è∞ K√∂vetkez≈ë friss√≠t√©s {self.update_interval / 3600:.0f} √≥ra m√∫lva...")
                time.sleep(self.update_interval)

            except Exception as e:
                logger.error(f"‚ùå Hiba a fut√°s sor√°n: {e}", exc_info=True)
                time.sleep(60)


if __name__ == '__main__':
    manager = MultiSiloManager()
    manager.run()
